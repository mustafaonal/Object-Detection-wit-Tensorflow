{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e76f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "752b00d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow model zoo\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeebe5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94708dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408155f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf8918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading TF model\n",
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29888c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install TF object detection\n",
    "if os.name=='posix':  \n",
    "    !apt-get install protobuf-compiler\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d3f3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8529050",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c03a307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: object_detection in c:\\users\\mustafa\\anaconda3\\lib\\site-packages\\object_detection-0.1-py3.8.egg (0.1)\n",
      "Collecting avro-python3\n",
      "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
      "Collecting apache-beam\n",
      "  Downloading apache_beam-2.30.0-cp38-cp38-win_amd64.whl (3.8 MB)\n",
      "Requirement already satisfied: pillow in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from object_detection) (8.2.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from object_detection) (4.6.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from object_detection) (3.3.4)\n",
      "Requirement already satisfied: Cython in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from object_detection) (0.29.23)\n",
      "Requirement already satisfied: contextlib2 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from object_detection) (0.6.0.post1)\n",
      "Requirement already satisfied: tf-slim in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from object_detection) (1.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from object_detection) (1.15.0)\n",
      "Collecting pycocotools\n",
      "  Using cached pycocotools-2.0.2.tar.gz (23 kB)\n",
      "Requirement already satisfied: lvis in c:\\users\\mustafa\\anaconda3\\lib\\site-packages\\lvis-0.5.3-py3.8.egg (from object_detection) (0.5.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from object_detection) (1.6.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from object_detection) (1.2.4)\n",
      "Requirement already satisfied: tf-models-official in c:\\users\\mustafa\\anaconda3\\lib\\site-packages\\tf_models_official-2.5.0-py3.8.egg (from object_detection) (2.5.0)\n",
      "Collecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: numpy<1.21.0,>=1.14.3 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from apache-beam->object_detection) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from apache-beam->object_detection) (2.8.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from apache-beam->object_detection) (2.25.1)\n",
      "Collecting fastavro<2,>=0.21.4\n",
      "  Downloading fastavro-1.4.2-cp38-cp38-win_amd64.whl (412 kB)\n",
      "Collecting pydot<2,>=1.2.0\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting oauth2client<5,>=2.0.1\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Collecting httplib2<0.20.0,>=0.8\n",
      "  Using cached httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from apache-beam->object_detection) (3.17.3)\n",
      "Requirement already satisfied: pytz>=2018.3 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from apache-beam->object_detection) (2021.1)\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from apache-beam->object_detection) (1.34.1)\n",
      "Collecting pymongo<4.0.0,>=3.8.0\n",
      "  Downloading pymongo-3.11.4-cp38-cp38-win_amd64.whl (383 kB)\n",
      "Requirement already satisfied: future<1.0.0,>=0.18.2 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from apache-beam->object_detection) (0.18.2)\n",
      "Collecting pyarrow<4.0.0,>=0.15.1\n",
      "  Downloading pyarrow-3.0.0-cp38-cp38-win_amd64.whl (12.7 MB)\n",
      "Collecting crcmod<2.0,>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "Collecting avro-python3\n",
      "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
      "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from apache-beam->object_detection) (3.7.4.3)\n",
      "Collecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from httplib2<0.20.0,>=0.8->apache-beam->object_detection) (2.4.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from oauth2client<5,>=2.0.1->apache-beam->object_detection) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from oauth2client<5,>=2.0.1->apache-beam->object_detection) (4.7.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from oauth2client<5,>=2.0.1->apache-beam->object_detection) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection) (1.26.4)\n",
      "Requirement already satisfied: cycler>=0.10.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from lvis->object_detection) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from lvis->object_detection) (1.3.1)\n",
      "Collecting opencv-python>=4.1.0.25\n",
      "  Using cached opencv_python-4.5.2.54-cp38-cp38-win_amd64.whl (34.7 MB)\n",
      "Requirement already satisfied: setuptools>=18.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from pycocotools->object_detection) (52.0.0.post20210125)\n",
      "Collecting gin-config\n",
      "  Using cached gin_config-0.4.0-py2.py3-none-any.whl (46 kB)\n",
      "Collecting google-api-python-client>=1.6.7\n",
      "  Downloading google_api_python_client-2.11.0-py2.py3-none-any.whl (7.0 MB)\n",
      "Collecting google-cloud-bigquery>=0.31.0\n",
      "  Downloading google_cloud_bigquery-2.20.0-py2.py3-none-any.whl (189 kB)\n",
      "Collecting kaggle>=1.3.9\n",
      "  Using cached kaggle-1.5.12-py3-none-any.whl\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.5.2.54-cp38-cp38-win_amd64.whl (34.6 MB)\n",
      "Requirement already satisfied: psutil>=5.4.3 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tf-models-official->object_detection) (5.8.0)\n",
      "Collecting py-cpuinfo>=3.3.0\n",
      "  Using cached py_cpuinfo-8.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tf-models-official->object_detection) (5.4.1)\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-win_amd64.whl (1.1 MB)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.13.0-cp38-cp38-win_amd64.whl (615 kB)\n",
      "Collecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.3.0-py3-none-any.whl (3.9 MB)\n",
      "Collecting tensorflow-hub>=0.6.0\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "Collecting tensorflow-model-optimization>=0.4.1\n",
      "  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211 kB)\n",
      "Requirement already satisfied: tensorflow>=2.5.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tf-models-official->object_detection) (2.5.0)\n",
      "Collecting google-api-core<2dev,>=1.21.0\n",
      "  Downloading google_api_core-1.30.0-py2.py3-none-any.whl (93 kB)\n",
      "Collecting google-auth-httplib2>=0.1.0\n",
      "  Using cached google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: google-auth<2dev,>=1.16.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from google-api-python-client>=1.6.7->tf-models-official->object_detection) (1.32.1)\n",
      "Collecting uritemplate<4dev,>=3.0.0\n",
      "  Using cached uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Using cached googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object_detection) (20.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\mustafa\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\mustafa\\\\AppData\\\\Local\\\\Temp\\\\pip-install-z69ybdub\\\\pycocotools_f2dd1ff459664e35b47c9c5beff5705a\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\mustafa\\\\AppData\\\\Local\\\\Temp\\\\pip-install-z69ybdub\\\\pycocotools_f2dd1ff459664e35b47c9c5beff5705a\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\mustafa\\AppData\\Local\\Temp\\pip-wheel-si9hdzci'\n",
      "       cwd: C:\\Users\\mustafa\\AppData\\Local\\Temp\\pip-install-z69ybdub\\pycocotools_f2dd1ff459664e35b47c9c5beff5705a\\\n",
      "  Complete output (16 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.8\n",
      "  creating build\\lib.win-amd64-3.8\\pycocotools\n",
      "  copying pycocotools\\coco.py -> build\\lib.win-amd64-3.8\\pycocotools\n",
      "  copying pycocotools\\cocoeval.py -> build\\lib.win-amd64-3.8\\pycocotools\n",
      "  copying pycocotools\\mask.py -> build\\lib.win-amd64-3.8\\pycocotools\n",
      "  copying pycocotools\\__init__.py -> build\\lib.win-amd64-3.8\\pycocotools\n",
      "  running build_ext\n",
      "  cythoning pycocotools/_mask.pyx to pycocotools\\_mask.c\n",
      "  C:\\Users\\mustafa\\anaconda3\\lib\\site-packages\\Cython\\Compiler\\Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: C:\\Users\\mustafa\\AppData\\Local\\Temp\\pip-install-z69ybdub\\pycocotools_f2dd1ff459664e35b47c9c5beff5705a\\pycocotools\\_mask.pyx\n",
      "    tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  building 'pycocotools._mask' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pycocotools\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\mustafa\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\mustafa\\\\AppData\\\\Local\\\\Temp\\\\pip-install-z69ybdub\\\\pycocotools_f2dd1ff459664e35b47c9c5beff5705a\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\mustafa\\\\AppData\\\\Local\\\\Temp\\\\pip-install-z69ybdub\\\\pycocotools_f2dd1ff459664e35b47c9c5beff5705a\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\mustafa\\AppData\\Local\\Temp\\pip-record-1u30j7kt\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\mustafa\\anaconda3\\Include\\pycocotools'\n",
      "         cwd: C:\\Users\\mustafa\\AppData\\Local\\Temp\\pip-install-z69ybdub\\pycocotools_f2dd1ff459664e35b47c9c5beff5705a\\\n",
      "    Complete output (14 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.8\n",
      "    creating build\\lib.win-amd64-3.8\\pycocotools\n",
      "    copying pycocotools\\coco.py -> build\\lib.win-amd64-3.8\\pycocotools\n",
      "    copying pycocotools\\cocoeval.py -> build\\lib.win-amd64-3.8\\pycocotools\n",
      "    copying pycocotools\\mask.py -> build\\lib.win-amd64-3.8\\pycocotools\n",
      "    copying pycocotools\\__init__.py -> build\\lib.win-amd64-3.8\\pycocotools\n",
      "    running build_ext\n",
      "    skipping 'pycocotools\\_mask.c' Cython extension (up-to-date)\n",
      "    building 'pycocotools._mask' extension\n",
      "    error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\mustafa\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\mustafa\\\\AppData\\\\Local\\\\Temp\\\\pip-install-z69ybdub\\\\pycocotools_f2dd1ff459664e35b47c9c5beff5705a\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\mustafa\\\\AppData\\\\Local\\\\Temp\\\\pip-install-z69ybdub\\\\pycocotools_f2dd1ff459664e35b47c9c5beff5705a\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\mustafa\\AppData\\Local\\Temp\\pip-record-1u30j7kt\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\mustafa\\anaconda3\\Include\\pycocotools' Check the logs for full command output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from google-auth<2dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object_detection) (4.2.2)\n",
      "Collecting google-resumable-media<2.0dev,>=0.6.0\n",
      "  Downloading google_resumable_media-1.3.1-py2.py3-none-any.whl (75 kB)\n",
      "Collecting proto-plus>=1.10.0\n",
      "  Downloading proto_plus-1.19.0-py3-none-any.whl (42 kB)\n",
      "Collecting google-cloud-core<2.0dev,>=1.4.1\n",
      "  Downloading google_cloud_core-1.7.1-py2.py3-none-any.whl (28 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Using cached google_crc32c-1.1.2-cp38-cp38-win_amd64.whl (34 kB)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official->object_detection) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official->object_detection) (2.20)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official->object_detection) (4.59.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official->object_detection) (1.1.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official->object_detection) (1.6.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official->object_detection) (0.13.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official->object_detection) (0.2.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official->object_detection) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official->object_detection) (1.12)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official->object_detection) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official->object_detection) (2.5.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official->object_detection) (1.1.2)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official->object_detection) (3.1.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official->object_detection) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official->object_detection) (0.36.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official->object_detection) (1.12.1)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorflow>=2.5.0->tf-models-official->object_detection) (2.5.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object_detection) (0.4.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object_detection) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object_detection) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object_detection) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object_detection) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object_detection) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object_detection) (3.1.1)\n",
      "Collecting dm-tree~=0.1.1\n",
      "  Using cached dm_tree-0.1.6-cp38-cp38-win_amd64.whl (75 kB)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Collecting portalocker==2.0.0\n",
      "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pywin32!=226 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from portalocker==2.0.0->sacrebleu->tf-models-official->object_detection) (227)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from seqeval->tf-models-official->object_detection) (0.24.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object_detection) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object_detection) (2.1.0)\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.12.1-py3-none-any.whl (17 kB)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.2.0-py3-none-any.whl (27 kB)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.1.0-py3-none-any.whl (48 kB)\n",
      "Collecting promise\n",
      "  Using cached promise-2.3-py3-none-any.whl\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from tensorflow-datasets->tf-models-official->object_detection) (20.3.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\mustafa\\anaconda3\\lib\\site-packages (from importlib-resources->tensorflow-datasets->tf-models-official->object_detection) (3.4.1)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Building wheels for collected packages: avro-python3, crcmod, dill, docopt, pycocotools, seqeval\n",
      "  Building wheel for avro-python3 (setup.py): started\n",
      "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
      "  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=487fb1501edadd6c93afb5ad285d2982e2bb503c3bccc89c3bd880a82e8e03cc\n",
      "  Stored in directory: c:\\users\\mustafa\\appdata\\local\\pip\\cache\\wheels\\a5\\f2\\87\\b7c4b9d5915716d94e8bf2e2f3bfbbd73bb5fe2a98677a59cb\n",
      "  Building wheel for crcmod (setup.py): started\n",
      "  Building wheel for crcmod (setup.py): finished with status 'done'\n",
      "  Created wheel for crcmod: filename=crcmod-1.7-py3-none-any.whl size=18838 sha256=2d84a919b7c42ad6432bffb90e7da783c9a19b4a819c724d5122a2fb6b0a6034\n",
      "  Stored in directory: c:\\users\\mustafa\\appdata\\local\\pip\\cache\\wheels\\ca\\5a\\02\\f3acf982a026f3319fb3e798a8dca2d48fafee7761788562e9\n",
      "  Building wheel for dill (setup.py): started\n",
      "  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78594 sha256=29fb0bd4ab27cee45ba29cb532fd7d00f25bfd3de7b8e6ec0580fc0b67af50e2\n",
      "  Stored in directory: c:\\users\\mustafa\\appdata\\local\\pip\\cache\\wheels\\07\\35\\78\\e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n",
      "  Building wheel for docopt (setup.py): started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=da5e9dda31b0ad2ed31e7cb5aa8fe2bb19c9a727dec28b50c57960df835f5bc9\n",
      "  Stored in directory: c:\\users\\mustafa\\appdata\\local\\pip\\cache\\wheels\\56\\ea\\58\\ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
      "  Building wheel for pycocotools (setup.py): started\n",
      "  Building wheel for pycocotools (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pycocotools\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16170 sha256=624149cd2f5e351bb25d47d9f3da546e34812d93326400060e59f7cb564d6fa8\n",
      "  Stored in directory: c:\\users\\mustafa\\appdata\\local\\pip\\cache\\wheels\\ad\\5c\\ba\\05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
      "Successfully built avro-python3 crcmod dill docopt seqeval\n",
      "Failed to build pycocotools\n",
      "Installing collected packages: googleapis-common-protos, text-unidecode, httplib2, google-crc32c, google-api-core, absl-py, uritemplate, typeguard, tensorflow-metadata, python-slugify, proto-plus, promise, portalocker, importlib-resources, google-resumable-media, google-cloud-core, google-auth-httplib2, docopt, dm-tree, dill, tensorflow-model-optimization, tensorflow-hub, tensorflow-datasets, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pymongo, pydot, pycocotools, pyarrow, py-cpuinfo, opencv-python-headless, opencv-python, oauth2client, kaggle, hdfs, google-cloud-bigquery, google-api-python-client, gin-config, fastavro, crcmod, avro-python3, apache-beam\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.13.0\n",
      "    Uninstalling absl-py-0.13.0:\n",
      "      Successfully uninstalled absl-py-0.13.0\n",
      "    Running setup.py install for pycocotools: started\n",
      "    Running setup.py install for pycocotools: finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "!pip install object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52257e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall protobuf matplotlib -y\n",
    "!pip install protobuf matplotlib==3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eedb5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2ce124e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version             Location\n",
      "---------------------------------- ------------------- ------------------------------------------------------------------------------------------\n",
      "absl-py                            0.12.0\n",
      "alabaster                          0.7.12\n",
      "anaconda-client                    1.7.2\n",
      "anaconda-navigator                 2.0.3\n",
      "anaconda-project                   0.9.1\n",
      "anyio                              2.2.0\n",
      "appdirs                            1.4.4\n",
      "argh                               0.26.2\n",
      "argon2-cffi                        20.1.0\n",
      "asn1crypto                         1.4.0\n",
      "astroid                            2.5\n",
      "astropy                            4.2.1\n",
      "astunparse                         1.6.3\n",
      "async-generator                    1.10\n",
      "atomicwrites                       1.4.0\n",
      "attrs                              20.3.0\n",
      "autopep8                           1.5.6\n",
      "Babel                              2.9.0\n",
      "backcall                           0.2.0\n",
      "backports.functools-lru-cache      1.6.4\n",
      "backports.shutil-get-terminal-size 1.0.0\n",
      "backports.tempfile                 1.0\n",
      "backports.weakref                  1.0.post1\n",
      "bcrypt                             3.2.0\n",
      "beautifulsoup4                     4.9.3\n",
      "bitarray                           1.9.2\n",
      "bkcharts                           0.2\n",
      "black                              19.10b0\n",
      "bleach                             3.3.0\n",
      "bokeh                              2.3.2\n",
      "boto                               2.49.0\n",
      "Bottleneck                         1.3.2\n",
      "brotlipy                           0.7.0\n",
      "cachetools                         4.2.2\n",
      "certifi                            2020.12.5\n",
      "cffi                               1.14.5\n",
      "chardet                            4.0.0\n",
      "click                              7.1.2\n",
      "cloudpickle                        1.6.0\n",
      "clyent                             1.2.2\n",
      "colorama                           0.4.4\n",
      "comtypes                           1.1.9\n",
      "conda                              4.10.1\n",
      "conda-build                        3.21.4\n",
      "conda-content-trust                0+unknown\n",
      "conda-package-handling             1.7.3\n",
      "conda-repo-cli                     1.0.4\n",
      "conda-token                        0.3.0\n",
      "conda-verify                       3.4.2\n",
      "contextlib2                        0.6.0.post1\n",
      "cryptography                       3.4.7\n",
      "cycler                             0.10.0\n",
      "Cython                             0.29.23\n",
      "cytoolz                            0.11.0\n",
      "dask                               2021.4.0\n",
      "decorator                          5.0.6\n",
      "defusedxml                         0.7.1\n",
      "diff-match-patch                   20200713\n",
      "dill                               0.3.1.1\n",
      "distributed                        2021.4.0\n",
      "dm-tree                            0.1.6\n",
      "docopt                             0.6.2\n",
      "docutils                           0.17\n",
      "entrypoints                        0.3\n",
      "et-xmlfile                         1.0.1\n",
      "fastcache                          1.1.0\n",
      "filelock                           3.0.12\n",
      "flake8                             3.9.0\n",
      "Flask                              1.1.2\n",
      "flatbuffers                        1.12\n",
      "fsspec                             0.9.0\n",
      "future                             0.18.2\n",
      "gast                               0.4.0\n",
      "gevent                             21.1.2\n",
      "glob2                              0.7\n",
      "google-api-core                    1.30.0\n",
      "google-auth                        1.32.1\n",
      "google-auth-httplib2               0.1.0\n",
      "google-auth-oauthlib               0.4.4\n",
      "google-cloud-core                  1.7.1\n",
      "google-crc32c                      1.1.2\n",
      "google-pasta                       0.2.0\n",
      "google-resumable-media             1.3.1\n",
      "googleapis-common-protos           1.53.0\n",
      "greenlet                           1.0.0\n",
      "grpcio                             1.34.1\n",
      "h5py                               3.1.0\n",
      "HeapDict                           1.0.1\n",
      "html5lib                           1.1\n",
      "httplib2                           0.19.1\n",
      "idna                               2.10\n",
      "imagecodecs                        2021.3.31\n",
      "imageio                            2.9.0\n",
      "imagesize                          1.2.0\n",
      "importlib-metadata                 3.10.0\n",
      "importlib-resources                5.2.0\n",
      "iniconfig                          1.1.1\n",
      "intervaltree                       3.1.0\n",
      "ipykernel                          5.3.4\n",
      "ipython                            7.22.0\n",
      "ipython-genutils                   0.2.0\n",
      "ipywidgets                         7.6.3\n",
      "isort                              5.8.0\n",
      "itsdangerous                       1.1.0\n",
      "jdcal                              1.4.1\n",
      "jedi                               0.17.2\n",
      "Jinja2                             2.11.3\n",
      "joblib                             1.0.1\n",
      "json5                              0.9.5\n",
      "jsonschema                         3.2.0\n",
      "jupyter                            1.0.0\n",
      "jupyter-client                     6.1.12\n",
      "jupyter-console                    6.4.0\n",
      "jupyter-core                       4.7.1\n",
      "jupyter-packaging                  0.7.12\n",
      "jupyter-server                     1.4.1\n",
      "jupyterlab                         3.0.14\n",
      "jupyterlab-pygments                0.1.2\n",
      "jupyterlab-server                  2.4.0\n",
      "jupyterlab-widgets                 1.0.0\n",
      "keras-nightly                      2.5.0.dev2021032900\n",
      "Keras-Preprocessing                1.1.2\n",
      "keyring                            22.3.0\n",
      "kiwisolver                         1.3.1\n",
      "lazy-object-proxy                  1.6.0\n",
      "libarchive-c                       2.9\n",
      "llvmlite                           0.36.0\n",
      "locket                             0.2.1\n",
      "lvis                               0.5.3\n",
      "lxml                               4.6.3\n",
      "Markdown                           3.3.4\n",
      "MarkupSafe                         1.1.1\n",
      "matplotlib                         3.3.4\n",
      "mccabe                             0.6.1\n",
      "menuinst                           1.4.16\n",
      "mistune                            0.8.4\n",
      "mkl-fft                            1.3.0\n",
      "mkl-random                         1.2.1\n",
      "mkl-service                        2.3.0\n",
      "mock                               4.0.3\n",
      "more-itertools                     8.7.0\n",
      "mpmath                             1.2.1\n",
      "msgpack                            1.0.2\n",
      "multipledispatch                   0.6.0\n",
      "mypy-extensions                    0.4.3\n",
      "navigator-updater                  0.2.1\n",
      "nbclassic                          0.2.6\n",
      "nbclient                           0.5.3\n",
      "nbconvert                          6.0.7\n",
      "nbformat                           5.1.3\n",
      "nest-asyncio                       1.5.1\n",
      "networkx                           2.5\n",
      "nltk                               3.6.1\n",
      "nose                               1.3.7\n",
      "notebook                           6.3.0\n",
      "numba                              0.53.1\n",
      "numexpr                            2.7.3\n",
      "numpy                              1.19.5\n",
      "numpydoc                           1.1.0\n",
      "oauthlib                           3.1.1\n",
      "object-detection                   0.1\n",
      "olefile                            0.46\n",
      "openpyxl                           3.0.7\n",
      "opt-einsum                         3.3.0\n",
      "packaging                          20.9\n",
      "pandas                             1.2.4\n",
      "pandocfilters                      1.4.3\n",
      "paramiko                           2.7.2\n",
      "parso                              0.7.0\n",
      "partd                              1.2.0\n",
      "path                               15.1.2\n",
      "pathlib2                           2.3.5\n",
      "pathspec                           0.7.0\n",
      "patsy                              0.5.1\n",
      "pep8                               1.7.1\n",
      "pexpect                            4.8.0\n",
      "pickleshare                        0.7.5\n",
      "Pillow                             8.2.0\n",
      "pip                                21.0.1\n",
      "pkginfo                            1.7.0\n",
      "pluggy                             0.13.1\n",
      "ply                                3.11\n",
      "portalocker                        2.0.0\n",
      "prometheus-client                  0.10.1\n",
      "promise                            2.3\n",
      "prompt-toolkit                     3.0.17\n",
      "proto-plus                         1.19.0\n",
      "protobuf                           3.17.3\n",
      "psutil                             5.8.0\n",
      "ptyprocess                         0.7.0\n",
      "py                                 1.10.0\n",
      "pyasn1                             0.4.8\n",
      "pyasn1-modules                     0.2.8\n",
      "pycodestyle                        2.6.0\n",
      "pycosat                            0.6.3\n",
      "pycparser                          2.20\n",
      "pycurl                             7.43.0.6\n",
      "pydocstyle                         6.0.0\n",
      "pydot                              1.4.2\n",
      "pyerfa                             1.7.3\n",
      "pyflakes                           2.2.0\n",
      "Pygments                           2.8.1\n",
      "pylint                             2.7.4\n",
      "pyls-black                         0.4.6\n",
      "pyls-spyder                        0.3.2\n",
      "pymongo                            3.11.4\n",
      "PyNaCl                             1.4.0\n",
      "pyodbc                             4.0.0-unsupported\n",
      "pyOpenSSL                          20.0.1\n",
      "pyparsing                          2.4.7\n",
      "pyreadline                         2.1\n",
      "pyrsistent                         0.17.3\n",
      "PySocks                            1.7.1\n",
      "pytest                             6.2.3\n",
      "python-dateutil                    2.8.1\n",
      "python-jsonrpc-server              0.4.0\n",
      "python-language-server             0.36.2\n",
      "python-slugify                     5.0.2\n",
      "pytz                               2021.1\n",
      "PyWavelets                         1.1.1\n",
      "pywin32                            227\n",
      "pywin32-ctypes                     0.2.0\n",
      "pywinpty                           0.5.7\n",
      "PyYAML                             5.4.1\n",
      "pyzmq                              20.0.0\n",
      "QDarkStyle                         2.8.1\n",
      "QtAwesome                          1.0.2\n",
      "qtconsole                          5.0.3\n",
      "QtPy                               1.9.0\n",
      "regex                              2021.4.4\n",
      "requests                           2.25.1\n",
      "requests-oauthlib                  1.3.0\n",
      "rope                               0.18.0\n",
      "rsa                                4.7.2\n",
      "Rtree                              0.9.7\n",
      "ruamel-yaml-conda                  0.15.100\n",
      "sacrebleu                          1.5.1\n",
      "scikit-image                       0.18.1\n",
      "scikit-learn                       0.24.1\n",
      "scipy                              1.6.2\n",
      "seaborn                            0.11.1\n",
      "Send2Trash                         1.5.0\n",
      "sentencepiece                      0.1.96\n",
      "seqeval                            1.2.2\n",
      "setuptools                         52.0.0.post20210125\n",
      "simplegeneric                      0.8.1\n",
      "singledispatch                     0.0.0\n",
      "sip                                4.19.13\n",
      "six                                1.15.0\n",
      "slim                               0.1                 c:\\users\\mustafa\\desktop\\object detection\\object_detection\\tensorflow\\models\\research\\slim\n",
      "sniffio                            1.2.0\n",
      "snowballstemmer                    2.1.0\n",
      "sortedcollections                  2.1.0\n",
      "sortedcontainers                   2.3.0\n",
      "soupsieve                          2.2.1\n",
      "Sphinx                             4.0.1\n",
      "sphinxcontrib-applehelp            1.0.2\n",
      "sphinxcontrib-devhelp              1.0.2\n",
      "sphinxcontrib-htmlhelp             1.0.3\n",
      "sphinxcontrib-jsmath               1.0.1\n",
      "sphinxcontrib-qthelp               1.0.3\n",
      "sphinxcontrib-serializinghtml      1.1.4\n",
      "sphinxcontrib-websupport           1.2.4\n",
      "spyder                             4.2.5\n",
      "spyder-kernels                     1.10.2\n",
      "SQLAlchemy                         1.4.7\n",
      "statsmodels                        0.12.2\n",
      "sympy                              1.8\n",
      "tables                             3.6.1\n",
      "tblib                              1.7.0\n",
      "tensorboard                        2.5.0\n",
      "tensorboard-data-server            0.6.1\n",
      "tensorboard-plugin-wit             1.8.0\n",
      "tensorflow                         2.5.0\n",
      "tensorflow-addons                  0.13.0\n",
      "tensorflow-datasets                4.3.0\n",
      "tensorflow-estimator               2.5.0\n",
      "tensorflow-hub                     0.12.0\n",
      "tensorflow-metadata                1.1.0\n",
      "tensorflow-model-optimization      0.6.0\n",
      "termcolor                          1.1.0\n",
      "terminado                          0.9.4\n",
      "testpath                           0.4.4\n",
      "text-unidecode                     1.3\n",
      "textdistance                       4.2.1\n",
      "tf-models-official                 2.5.0\n",
      "tf-slim                            1.1.0\n",
      "threadpoolctl                      2.1.0\n",
      "three-merge                        0.1.1\n",
      "tifffile                           2021.4.8\n",
      "toml                               0.10.2\n",
      "toolz                              0.11.1\n",
      "tornado                            6.1\n",
      "tqdm                               4.59.0\n",
      "traitlets                          5.0.5\n",
      "typed-ast                          1.4.2\n",
      "typeguard                          2.12.1\n",
      "typing-extensions                  3.7.4.3\n",
      "ujson                              4.0.2\n",
      "unicodecsv                         0.14.1\n",
      "uritemplate                        3.0.1\n",
      "urllib3                            1.26.4\n",
      "watchdog                           1.0.2\n",
      "wcwidth                            0.2.5\n",
      "webencodings                       0.5.1\n",
      "Werkzeug                           1.0.1\n",
      "wheel                              0.36.2\n",
      "widgetsnbextension                 3.5.1\n",
      "win-inet-pton                      1.1.0\n",
      "win-unicode-console                0.5\n",
      "wincertstore                       0.2\n",
      "wrapt                              1.12.1\n",
      "xlrd                               2.0.1\n",
      "XlsxWriter                         1.3.8\n",
      "xlwings                            0.23.0\n",
      "xlwt                               1.3.0\n",
      "xmltodict                          0.12.0\n",
      "yapf                               0.31.0\n",
      "zict                               2.0.0\n",
      "zipp                               3.4.1\n",
      "zope.event                         4.5.0\n",
      "zope.interface                     5.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3903cf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [........................................................................] 20515344 / 20515344        1 file(s) moved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "x ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fceee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'livelong', 'id':1}, {'name':'okay', 'id':2}, {'name':'thankyou', 'id':3}, {'name':'thumbsdown', 'id':4}, {'name':'thumbsleft', 'id':5}, {'name':'thumbsright', 'id':6}, {'name':'thumbsup', 'id':7}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08171f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL IF RUNNING ON COLAB\n",
    "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
    "if os.path.exists(ARCHIVE_FILES):\n",
    "  !tar -zxvf {ARCHIVE_FILES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e1c8909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Tensorflow\\scripts'...\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52748f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow\\workspace\\annotations\\train.record\n",
      "Successfully created the TFRecord file: Tensorflow\\workspace\\annotations\\test.record\n"
     ]
    }
   ],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f429d0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1 file(s) copied.\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c98f735c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'eval_pb2' from 'object_detection.protos' (C:\\Users\\mustafa\\Desktop\\Object Detection\\object_detection\\lib\\site-packages\\object_detection\\protos\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19956/880287751.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotos\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtext_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Object Detection\\object_detection\\lib\\site-packages\\object_detection\\utils\\config_util.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotos\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0meval_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotos\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgraph_rewriter_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotos\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minput_reader_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'eval_pb2' from 'object_detection.protos' (C:\\Users\\mustafa\\Desktop\\Object Detection\\object_detection\\lib\\site-packages\\object_detection\\protos\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eaf1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d9a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7dac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9032e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3e6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc9570",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb1de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a708c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1594e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e4bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-5')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f261061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8a7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca279d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'livelong.02533422-940e-11eb-9dbd-5cf3709bbcc6.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b906c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2b5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall opencv-python-headless -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b141be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f64bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6beb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c854cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf7158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5350894",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7c2948",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c317e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f1e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21f435",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1333ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd10124",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc312c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
    "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7158f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tflite_convert \\\n",
    "--saved_model_dir={} \\\n",
    "--output_file={} \\\n",
    "--input_shapes=1,300,300,3 \\\n",
    "--input_arrays=normalized_input_image_tensor \\\n",
    "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
    "--inference_type=FLOAT \\\n",
    "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9590ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8575795",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "object_detection",
   "language": "python",
   "name": "object_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
